{
  "$schema": "https://mintlify.com/docs.json",
  "theme": "mint",
  "name": "LLM Stats",
  "description": "LLM Stats is powered by ZeroEval, the open-source evaluation library built by the LLM Stats team",
  "colors": {
    "primary": "#4B4FED",
    "dark": "#818CF8",
    "light": "#6366F1"
  },
  "appearance": {
    "default": "system"
  },
  "background": {
    "color": {
      "light": "#FFFFFF",
      "dark": "#09090B"
    }
  },
  "font": {
    "family": "Geist",
    "heading": {
      "family": "Geist",
      "weight": 600
    }
  },
  "styling": {
    "codeblocks": {
      "theme": {
        "light": "github-light",
        "dark": "github-dark"
      }
    }
  },
  "favicon": "/favicon.svg",
  "logo": {
    "light": "/logo/light.svg",
    "dark": "/logo/dark.svg",
    "href": "https://llm-stats.com"
  },
  "navigation": {
    "tabs": [
      {
        "tab": "Documentation",
        "groups": [
          {
            "group": "Getting Started",
            "pages": [
              "index",
              "quickstart",
              "python-sdk/installation",
              "python-sdk/quickstart"
            ]
          },
          {
            "group": "Datasets",
            "pages": [
              "python-sdk/datasets/creating",
              "python-sdk/datasets/loading",
              "python-sdk/datasets/versioning-and-subsets",
              "python-sdk/datasets/multimodal"
            ]
          },
          {
            "group": "Evals",
            "pages": [
              "python-sdk/evals/running-evals",
              "python-sdk/evals/scoring-and-metrics",
              "python-sdk/evals/repetitions-and-resume",
              "python-sdk/evals/common-failures"
            ]
          },
          {
            "group": "CLI",
            "pages": [
              "python-sdk/cli/using-the-cli"
            ]
          },
          {
            "group": "Examples",
            "pages": [
              "python-sdk/examples/text-eval-end-to-end",
              "python-sdk/examples/multimodal-eval-end-to-end"
            ]
          }
        ]
      }
    ],
    "global": {
      "anchors": [
        {
          "anchor": "SDK on PyPI",
          "href": "https://pypi.org/project/zeroeval/",
          "icon": "box-open"
        },
        {
          "anchor": "LLM Stats App",
          "href": "https://llm-stats.com",
          "icon": "chart-bar"
        }
      ]
    }
  },
  "navbar": {
    "links": [
      {
        "label": "Support",
        "href": "mailto:founders@llm-stats.com"
      }
    ],
    "primary": {
      "type": "button",
      "label": "Go to App",
      "href": "https://llm-stats.com"
    }
  },
  "contextual": {
    "options": [
      "copy",
      "view",
      "chatgpt",
      "claude",
      "perplexity",
      "mcp",
      "cursor",
      "vscode"
    ]
  },
  "footer": {
    "socials": {
      "website": "https://llm-stats.com"
    }
  }
}
